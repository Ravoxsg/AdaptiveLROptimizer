\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{krizhevsky2012imagenet}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{polyak1964some}
\citation{hinton2006training}
\citation{hinton2006reducing}
\citation{lecun1998gradient}
\citation{martens2010deep}
\citation{duchi2011adaptive}
\citation{zeiler2012adadelta}
\citation{kingma2014adam}
\citation{lecun1998gradient}
\citation{martens2010deep}
\citation{schaul2013no}
\citation{martens2010deep}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{2}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Adaptive learning rate}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}First-order method}{2}{subsection.3.1}}
\citation{martens2010deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Second-order method}{3}{subsection.3.2}}
\citation{boston}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{4}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Practical considerations}{4}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Results}{4}{subsection.4.2}}
\citation{xiao2017fashion}
\citation{cifar}
\citation{krizhevsky2012imagenet}
\citation{he2016deep}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Linear regression}{5}{subsubsection.4.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Basic, first-order, and second-order methods training and test losses over time}}{5}{figure.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Logistic regression}{5}{subsubsection.4.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Image classification with neural networks}{5}{subsubsection.4.2.3}}
\citation{he2016deep}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Second-order and basic methods with LeNet, initial learning rate: 0.01}}{6}{figure.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Second-order and basic methods with ResNet, initial learning rate: 0.1}}{6}{figure.3}}
\citation{cifar}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Learning rate variations, LeNet and ResNet, Cifar-10}}{7}{figure.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Second-order basic methods with ResNet, initial learning rate: 0.01}}{7}{figure.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces First-order basic methods with ResNet, initial learning rate: 0.1}}{7}{figure.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Second-order basic methods with ResNet on Cifar-100, initial learning rate: 0.02}}{8}{figure.7}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Further exploration}{8}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Learning the learning rate}{8}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Second-order adaptive learning rate and basic method with ResNet, initial learning rate 0.05}}{8}{figure.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Momentum}{8}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Getting loss values via a validation set}{8}{subsection.5.3}}
\citation{kingma2014adam}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Second-order with momentum and basic methods with ResNet, initial learning rate: 0.1}}{9}{figure.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Second-order with val. sampling and basic methods with ResNet, initial learning rate: 0.1}}{9}{figure.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Comparison with other optimizers}{9}{subsection.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Second-order and basic method using Adam with ResNet, initial learning rate: 0.1}}{9}{figure.11}}
\bibstyle{plain}
\bibdata{ref}
\@writefile{toc}{\contentsline {section}{\numberline {6}Limitations}{10}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Choice of step $\epsilon $}{10}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Choice of the initial learning rate}{10}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Cost of loss computations}{10}{subsection.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Overfitting}{10}{subsection.6.4}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{10}{section.7}}
\bibcite{boston}{{1}{}{{}}{{}}}
\bibcite{cifar}{{2}{}{{}}{{}}}
\bibcite{duchi2011adaptive}{{3}{}{{}}{{}}}
\bibcite{he2016deep}{{4}{}{{}}{{}}}
\bibcite{hinton2006training}{{5}{}{{}}{{}}}
\bibcite{hinton2006reducing}{{6}{}{{}}{{}}}
\bibcite{kingma2014adam}{{7}{}{{}}{{}}}
\bibcite{krizhevsky2012imagenet}{{8}{}{{}}{{}}}
\bibcite{lecun1998gradient}{{9}{}{{}}{{}}}
\bibcite{martens2010deep}{{10}{}{{}}{{}}}
\bibcite{polyak1964some}{{11}{}{{}}{{}}}
\bibcite{schaul2013no}{{12}{}{{}}{{}}}
\bibcite{xiao2017fashion}{{13}{}{{}}{{}}}
\bibcite{zeiler2012adadelta}{{14}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
